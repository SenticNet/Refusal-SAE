{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6409ad1",
   "metadata": {},
   "source": [
    "# Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6327b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-08 17:46:12 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x15542787b6a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.utils import *\n",
    "from utils.plot_utils import *\n",
    "from utils.data_utils import *\n",
    "from utils.eval_refusal import *\n",
    "from utils.attribution_utils import *\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict,Counter\n",
    "import os\n",
    "from utils.gemmascope import JumpReLUSAE_Base,get_optimal_file\n",
    "from sae_lens import SAE\n",
    "from transformer_lens import utils, HookedTransformer\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from einops import einsum\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import requests\n",
    "import pandas as pd\n",
    "import gc\n",
    "with open('openai_key.txt','r') as f:\n",
    "    openai_key = f.read().strip()\n",
    "os.environ['OPENAI_API_KEY'] = openai_key\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.set_grad_enabled(False) # rmb set to true for grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded87d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d71fbb2a1214cb491039a9ebb66a82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# Load model and SAE\n",
    "\n",
    "device = 'cuda:0'\n",
    "torch_dtype = torch.bfloat16\n",
    "model_name = \"google/gemma-2-2b\"\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    model_name,\n",
    "    center_unembed=False,\n",
    "    center_writing_weights=False,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=False,\n",
    "    default_padding_side = 'left',\n",
    "    default_prepend_bos = True,\n",
    "    torch_dtype = torch_dtype,\n",
    "    device = device\n",
    ")  \n",
    "model.tokenizer.add_bos_token=True\n",
    "\n",
    "# Load sae\n",
    "size = '65k' if 'gemma' in model_name else '32k'\n",
    "sae_layers = model.cfg.n_layers\n",
    "saes = {}\n",
    "comps = ['res']\n",
    "\n",
    "sae_naming = {\n",
    "    'res': 'blocks.{l}.hook_resid_post',\n",
    "    'mlp': 'blocks.{l}.hook_mlp_post',\n",
    "    'attn': 'blocks.{l}.attn.hook_z',\n",
    "}\n",
    "for comp in comps:\n",
    "    sae_key_fn = sae_naming[comp]\n",
    "    for layer in range(sae_layers):\n",
    "        if 'gemma' in model_name:\n",
    "            repo_id = f\"google/gemma-scope-2b-pt-res\"\n",
    "            sae_path = get_optimal_file(repo_id, layer,size)\n",
    "            saes[sae_key_fn.format(l=layer)] = JumpReLUSAE_Base.from_pretrained(repo_id, sae_path, device).to(torch_dtype).to(device)\n",
    "        else:\n",
    "            sae,_,_=SAE.from_pretrained(release=\"llama_scope_lxr_8x\", sae_id=f\"l{layer}r_8x\", device=device)\n",
    "            saes[sae_key_fn.format(l=layer)] = sae.to(torch_dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c09b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "saes_descriptions = defaultdict(defaultdict)\n",
    "comps = ['res']\n",
    "\n",
    "if 'gemma' in model_name.lower(): # llama cant export for some reason, only can take ad-hoc feature\n",
    "    url = f\"https://www.neuronpedia.org/api/explanation/export?modelId=gemma-2-2b&saeId={layer}-gemmascope-{comp}-{size}\"\n",
    "    neuropedia_path = f'{\"gemma\" if \"gemma\" in model_name.lower() else \"llama\"}_res_neuropedia.pkl'\n",
    "    if not os.path.exists(neuropedia_path): # takes 5 min, just cache them for later use.\n",
    "        for layer in tqdm(range(model.cfg.n_layers),total = model.cfg.n_layers):\n",
    "            for comp in comps:\n",
    "                \n",
    "                headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "                response = requests.get(url, headers=headers)\n",
    "                data = response.json()\n",
    "                explanations_df = pd.DataFrame(data)\n",
    "                # # rename index to \"feature\"\n",
    "                explanations_df.rename(columns={\"index\": \"feature\"}, inplace=True)\n",
    "                explanations_df[\"feature\"] = explanations_df[\"feature\"].astype(int)\n",
    "                explanations_df[\"description\"] = explanations_df[\"description\"].apply(\n",
    "                    lambda x: x.lower()\n",
    "                )\n",
    "                saes_descriptions[layer][comp] = explanations_df\n",
    "        with open(neuropedia_path,'wb') as f:\n",
    "            pickle.dump(saes_descriptions,f)\n",
    "    else:\n",
    "        with open(neuropedia_path,'rb') as f:\n",
    "            saes_descriptions = pickle.load(f)\n",
    "\n",
    "def get_feat_description(feat,layer,comp = 'res'): # get the description given feature and layer\n",
    "    if 'gemma' in model_name:\n",
    "        df = saes_descriptions[layer][comp]\n",
    "        try:\n",
    "            return df[df[\"feature\"] == feat][\"description\"].iloc[0]\n",
    "        except:\n",
    "            return \"No description found\"\n",
    "    else:\n",
    "        api_url = \"https://www.neuronpedia.org/api/feature/llama3.1-8b/{l}-llamascope-res-{size}/{f}\"\n",
    "        try:\n",
    "            data = requests.get(api_url.format(l=layer,f=feat,size= size)).json()\n",
    "            return data[\"explanations\"][0][\"description\"]\n",
    "        except:\n",
    "            return \"No description found\"\n",
    "\n",
    "html_template = \"https://neuronpedia.org/{}/{}/{}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "def get_dashboard_html(model = \"gemma-2-2b\", layer=0, feature_idx=0):\n",
    "    html_ = html_template.format(model, f'{layer}-{\"gemmascope\" if \"gemma\" in model else \"llamascope\"}-res-{size}', feature_idx)\n",
    "    return html_\n",
    "\n",
    "def get_max_act_approx(layer, feature_idx): # some fn to get the max act of a feature\n",
    "    url = f\"https://www.neuronpedia.org/api/feature/{'gemma-2-2b' if 'gemma' in model_name else 'llama3.1-8b'}/{layer}-{'gemmascope' if 'gemma' in model_name else 'llamascope'}-res-{size}/{feature_idx}\"\n",
    "\n",
    "    headers = {\"X-Api-Key\": \"YOUR_SECRET_TOKEN\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    return response.json()['maxActApprox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0148bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from typing import Any, Callable, Literal, TypeAlias\n",
    "AnsConfig = namedtuple(\"AnsConfig\", [\"a\", \"b\", \"operation\", \"ans\",\"a_ans\"])\n",
    "\n",
    "def prompt_generator(\n",
    "    n_range: int = 100,\n",
    "    op: list[str] = [\"plus\"],\n",
    "    n_batch: int = 100,\n",
    "    return_type: Literal[\"string\", \"token\"] = \"string\",\n",
    "    write_to_file: bool = False,\n",
    "    file_path: str = \"addition_prompts.txt\",\n",
    "    with_instructions: bool = False,\n",
    ") -> tuple[list[str], list[AnsConfig]]:\n",
    "    \"\"\"\n",
    "    Generates a list of arithmetic questions and their answers.\n",
    "    \"\"\"\n",
    "    a = torch.randint(0, n_range, (n_batch,))\n",
    "    aa = a + 10\n",
    "    b = torch.randint(0, n_range, (n_batch,))\n",
    "    \n",
    "    a_instr = torch.randint(0, n_range, (n_batch,))\n",
    "    b_instr = torch.randint(0, n_range, (n_batch,))\n",
    "    \n",
    "    ans_list = []\n",
    "    q_list = []\n",
    "    \n",
    "    \n",
    "    with open(file_path, \"w\") as f:\n",
    "        for i in range(n_batch):\n",
    "            \n",
    "            operation = random.choice(op)\n",
    "\n",
    "            # log the correct answer\n",
    "            if operation == \"plus\":\n",
    "                answer = a[i] + b[i]\n",
    "                inst_answer = a_instr[i] + b_instr[i]\n",
    "                alt_answer = aa[i] + b[i]\n",
    "            elif operation == \"minus\":\n",
    "                answer = a[i] - b[i]\n",
    "                inst_answer = a_instr[i] - b_instr[i]\n",
    "                alt_answer = aa[i] - b[i]\n",
    "            elif operation == \"times\":\n",
    "                answer = a[i] * b[i]\n",
    "                inst_answer = a_instr[i] * b_instr[i]\n",
    "                alt_answer = aa[i] * b[i]\n",
    "            # elif operation == \"divided by\":\n",
    "            #     answer = a[i] / b[i]\n",
    "            \n",
    "            if with_instructions:\n",
    "                q_list.append(\n",
    "                    f\"{a_instr[i].item()} {operation} {b_instr[i].item()} is {inst_answer.item()}, {a[i].item()} {operation} {b[i].item()} is\"\n",
    "                )\n",
    "            else:\n",
    "                q_list.append(\n",
    "                    (f\"{a[i].item()} {operation} {b[i].item()} is\",f\"{aa[i].item()} {operation} {b[i].item()} is\")\n",
    "                )\n",
    "\n",
    "            if write_to_file:\n",
    "                f.write(q_list[-1] + \"\\n\")\n",
    "            \n",
    "            ans_list.append(\n",
    "                AnsConfig(\n",
    "                    a=a[i].item(),\n",
    "                    b=b[i].item(),\n",
    "                    operation=operation,\n",
    "                    ans=answer.item(),\n",
    "                    a_ans=alt_answer.item()\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return q_list, ans_list\n",
    "\n",
    "### Testing functionality\n",
    "q_list, a_list = prompt_generator(with_instructions=False, n_batch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c315468b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "1\n",
      "['97', '100', '102', '164', '58', '66', '66', '46', '106', '102']\n",
      "['107', '110', '112', '174', '68', '76', '76', '56', '116', '112']\n"
     ]
    }
   ],
   "source": [
    "clean_prompts = [x[0] for x in q_list]\n",
    "corrupt_prompts = [x[1] for x in q_list]\n",
    "\n",
    "clean_ans = [str(x.ans) for x in a_list]\n",
    "corrupt_ans = [str(x.a_ans) for x in a_list]\n",
    "\n",
    "clean_ans_logit = [model.tokenizer.encode(x,add_special_tokens=False)[0] for x in clean_ans]\n",
    "corrupt_ans_logit = [model.tokenizer.encode(x,add_special_tokens=False)[0] for x in corrupt_ans]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "deeff74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['97', '100', '102', '164', '58', '66', '66', '46', '106', '102']\n",
      "['107', '110', '112', '174', '68', '76', '76', '56', '116', '112']\n"
     ]
    }
   ],
   "source": [
    "print (clean_ans)\n",
    "print (corrupt_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ea10774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_attribution(model,saes,ds,interpolate_steps = 1):\n",
    "    \"\"\"\n",
    "    Use linear attribution to get the features for each token\n",
    "    \"\"\"\n",
    "\n",
    "    clean_prompts = [x['clean_prompt'] for x in ds]\n",
    "    corrupt_prompts = [x['corrupt_prompt'] for x in ds]\n",
    "    clean_id = [x['clean_ans'] for x in ds]\n",
    "    corrupt_id = [x['corrupt_ans'] for x in ds]\n",
    "\n",
    "    def metric_fn(x):\n",
    "        clean_logit = x[torch.arange(x.shape[0]),-1,clean_id]\n",
    "        corrupt_logit = x[torch.arange(x.shape[0]),-1,corrupt_id]\n",
    "        return corrupt_logit - clean_logit\n",
    "    \n",
    "    clean_input_ids = model.tokenizer(clean_prompts,return_tensors='pt',padding='longest').to(model.cfg.device)\n",
    "    corrupt_input_ids = model.tokenizer(corrupt_prompts,return_tensors='pt',padding='longest').to(model.cfg.device)\n",
    "    \n",
    "    patch_cache = defaultdict(dict)\n",
    "    clean_cache = {}\n",
    "    with torch.no_grad():\n",
    "        # Get patch = steered states\n",
    "        model.reset_hooks()\n",
    "        model.add_hook(resid_name_filter,partial(store_sae_feat,saes = saes,cache = patch_cache,store_error=True))\n",
    "        _ = model(corrupt_input_ids.input_ids,attention_mask = corrupt_input_ids.attention_mask)\n",
    "        model.reset_hooks()\n",
    "\n",
    "        # get clean\n",
    "        model.add_hook(resid_name_filter,partial(store_sae_feat,saes = saes,cache = clean_cache))\n",
    "        _ = model(clean_input_ids.input_ids,attention_mask = clean_input_ids.attention_mask)\n",
    "        model.reset_hooks()\n",
    "    \n",
    "    torch.set_grad_enabled(True) # allow grads\n",
    "    # get grads (interpolate average across steps)\n",
    "    all_grads = defaultdict(list)\n",
    "    for step in range(interpolate_steps):\n",
    "        model.reset_hooks()\n",
    "        alpha = step/interpolate_steps\n",
    "        grad_cache = {}\n",
    "        model.add_hook(resid_name_filter,partial(sae_grad_patch_IG,grad_cache = grad_cache,saes=saes,patch_cache = patch_cache,alpha=alpha))\n",
    "        model.add_hook(resid_name_filter,sae_bwd_hook,'bwd')\n",
    "        logits = model(clean_input_ids.input_ids,attention_mask = clean_input_ids.attention_mask)\n",
    "        loss = metric_fn(logits).mean()\n",
    "        logits.grad = None\n",
    "        for v in grad_cache.values():\n",
    "            v.grad = None\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l,acts in grad_cache.items():\n",
    "                all_grads[l].append(acts.grad.detach())\n",
    "        del grad_cache\n",
    "        torch.cuda.empty_cache()\n",
    "    all_grads = {k:torch.stack(v).mean(0) for k,v in all_grads.items()}\n",
    "    attrs = {}\n",
    "\n",
    "    for l,clean_acts in clean_cache.items():\n",
    "        delt = patch_cache['feat'][l] - clean_acts\n",
    "        attrs[l] = (delt * all_grads[l]).detach().cpu()\n",
    "    \n",
    "    model.reset_hooks()\n",
    "    del patch_cache\n",
    "    del clean_cache\n",
    "    del all_grads\n",
    "    torch.set_grad_enabled(False)\n",
    "    clear_mem()\n",
    "    return attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25290a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Check acc\n",
    "clean_prompts_inps = model.tokenizer([x +' ' for x in clean_prompts],return_tensors='pt',padding='longest').to(model.cfg.device)\n",
    "clean_logit = model(clean_prompts_inps.input_ids,attention_mask = clean_prompts_inps.attention_mask)[:,-1].argmax(-1).detach().cpu().tolist()\n",
    "\n",
    "print (np.mean([x == y for x,y in zip(clean_logit,clean_ans_logit)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b30e33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [{'clean_prompt': clean_prompts[i],'corrupt_prompt': corrupt_prompts[i],'clean_ans': clean_ans_logit[i],'corrupt_ans': corrupt_ans_logit[i]} for i in range(len(clean_prompts))]\n",
    "\n",
    "circuit = linear_attribution(model,saes,ds,interpolate_steps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f758606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features above threshold: 15.6\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.01\n",
    "threshold_cir,n_feats = create_circuit_mask(circuit,threshold,clamp_val = 0,device = model.cfg.device)\n",
    "print (f\"Number of features above threshold: {n_feats}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a1bdec13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 27 plus 70 is\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1, Feature 31864, tokens: ['2'],description: numerical values\n",
      "Layer 2, Feature 297, tokens: ['2'],description:  numerical values, particularly in forms of measurements or identifiers\n",
      "Layer 3, Feature 33275, tokens: ['2'],description:  numerical values, particularly those that are significant or used in various contexts\n",
      "Layer 5, Feature 39350, tokens: ['2'],description: references to dates or numerical data\n",
      "Layer 6, Feature 17003, tokens: ['2'],description:  occurrences of numeric representations and mathematical functions\n",
      "Layer 7, Feature 56376, tokens: ['2'],description:  numeric values\n",
      "Layer 9, Feature 40150, tokens: ['2'],description:  numerical identifiers or designations in mathematical contexts\n",
      "Layer 10, Feature 26348, tokens: ['2'],description:  patterns and relationships in mathematical expressions\n",
      "Layer 11, Feature 22636, tokens: ['2'],description: numbers and mathematical concepts, particularly involving prime factors\n",
      "Layer 13, Feature 48615, tokens: ['2'],description:  references to the version numbers of python packages or libraries\n",
      "Layer 2, Feature 1654, tokens: ['7'],description:  numerical values related to legal or procedural concepts\n",
      "Layer 2, Feature 2288, tokens: ['7'],description:  numerical values and statistics related to age, ratings, or percentages\n",
      "Layer 20, Feature 1339, tokens: ['▁is'],description: negative numerical values and their context in discussions\n",
      "Layer 25, Feature 4448, tokens: ['▁is'],description:  mathematical expressions involving derivatives and calculations\n"
     ]
    }
   ],
   "source": [
    "encoded_input = model.tokenizer(clean_prompts,return_tensors='pt',padding='longest').input_ids\n",
    "\n",
    "sae_circuit_list,encoded_input = circuit_tolist(threshold_cir,encoded_input,remove_padding=True,ignore_bos = True)\n",
    "sample_id = 0\n",
    "sample_circuit = sae_circuit_list[sample_id]\n",
    "sample_tokens = model.tokenizer.convert_ids_to_tokens(encoded_input[sample_id])\n",
    "\n",
    "all_feats = []\n",
    "token_feats_counts = []\n",
    "feat_to_tokens = defaultdict(list)\n",
    "for j,xx in enumerate(sample_circuit):\n",
    "    all_feats.extend(xx)\n",
    "    token_feats_counts.append(len(xx))\n",
    "    for x in xx:\n",
    "        feat_to_tokens[x].append(sample_tokens[j])\n",
    "\n",
    "print (f'Prompt: {clean_prompts[sample_id]}')\n",
    "plot_bar(token_feats_counts, x_tick=[str(x) if x != '\\n' else '<newline>' for x in sample_tokens], ylabel='Num feats', xlabel='Tokens', title='Num feats per token')\n",
    "\n",
    "for l,f in all_feats:\n",
    "    print (f'Layer {l}, Feature {f}, tokens: {feat_to_tokens[(l,f)]},description: {get_feat_description(f,l)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed94b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
